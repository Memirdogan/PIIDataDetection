{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/emdogan/pii-data-detection-train-with-w-b-train-py-tercume?scriptVersionId=166841779\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nfrom itertools import chain\nfrom functools import partial\nfrom transformers import AutoTokenizer, TrainingArguments\nfrom transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\nimport pandas as pd\nfrom types import SimpleNamespace\nimport torch\nimport wandb\nimport spacy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary functions and classes from other files\nfrom metric import compute_metrics\nfrom data import create_dataset\nfrom utils import get_reference_df, parse_predictions\nfrom utils import filter_errors, generate_htmls_concurrently, visualize, convert_for_upload\nfrom utils import CustomTrainer\nfrom utils import upload_kaggle_dataset, parse_args","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the project name for Weights & Biases\nWANDB_PROJECT = 'pii'\n\n# Define the configuration for the experiment\nconfig = SimpleNamespace(\n    experiment='pii000',\n    threshold=0.6,\n    o_weight=0.05,\n    stride_artifact='darek/pii/processed_data:v3',\n    raw_artifact='darek/pii/raw_data:v3',\n    external_data_1='none',\n    external_data_2='none',\n    external_data_3='none',\n    external_data_4='none',\n    external_data_5='none',\n    output_dir=\"output\",\n    inference_max_length=768,\n    training_max_length=512,\n    training_model_path=\"microsoft/deberta-v3-large\",\n    fp16=True,\n    learning_rate=1e-5,\n    num_train_epochs=0.1,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    gradient_accumulation_steps=2,\n    report_to=\"wandb\",\n    evaluation_strategy=\"epoch\",\n    do_eval=True,\n    save_total_limit=1,\n    logging_steps=10,\n    lr_scheduler_type='cosine',\n    warmup_ratio=0.1,\n    weight_decay=0.01,\n)\n\n\"\"\"\n---------------------------------------------\n- W&B projesinin adı pii olarak belirlenmiş ve config yani yapılandırma yapılmış\n\n+ experiment='pii000' projenin kimliği pii000 olarak belirlenmiş\n+ threshold=0.6 güvenilirlik eşik değeri 0.6 yani %60 olarak belirlenmiş\n+ o_weight=0.05 \"o\" etiketinin ağırlığı %50 olarak belirlenmiş\n+ output_dir=\"output\" output direction yani çıkış dizisi output olarak belirlenmiş\n+ inference_max_length=768 modelin tek bir giriş metni için işleyebileceği maksimum token sayısı 768 belirlenmiş\n+ training_max_length=512 modelin bir eğitim örneğini işlerken kullanabileceği maksimum token sayısı 512 belirlenmiş\n+ training_model_path=\"microsoft/deberta-v3-large\" eğitimde kullanılcak model deberta3\n+ fp16=True yarı hassas hesaplama aktif edilmiş\n+ num_train_epochs=0.1 döngü sayısı belirlenmiş\n+ report_to=\"wandb\" raporların W&B ye iletilmesi istenmiş\n+ evaluation_strategy=\"epoch\" değerlendirme stratejisi epoch olarak belirlenmiş\n---------------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(config):\n    # Initialize Weights & Biases\n    wandb.init(project=WANDB_PROJECT, job_type='train', config=config)\n    config = wandb.config\n\n    # Load the data\n    stride_artifact = wandb.use_artifact(config.stride_artifact)\n    stride_artifact_dir = stride_artifact.download()\n    df = pd.read_parquet(stride_artifact_dir + '/stride_data.parquet')\n    train_df = df[df.valid == False].reset_index(drop=True)\n    eval_df = df[df.valid == True].reset_index(drop=True)\n\n\"\"\"\n------------------------------------------\n- verileri yükleme ve yapılandırma yapmamızı sağlar, W&B kullanarak deney başladır.\n\n+ wandb.init komutunu kullanarak W&B platformunu başlatır ve projeye train türünde deney başlatır\n+ wandb.use_artifact ile W&B'deki depolanan veri artifactini kullanır\n+ bu artifactlar df'e atanır ve sonrasında valid sütunu kullanılarak train ve eval olmak üzere ikiye ayrılır\n------------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Load external data\n    for art in [config.external_data_1, config.external_data_2, config.external_data_3, config.external_data_4, config.external_data_5]:\n        if art != 'none':\n            print(f'Loading external data {art}...')\n            artifact = wandb.use_artifact(art)\n            artifact_dir = artifact.download()\n            ext_df = pd.read_parquet(artifact_dir + '/ext_data.parquet')\n            train_df = pd.concat([train_df, ext_df], ignore_index=True)\n\n\"\"\"\n---------------------------------------\n- bu döngü dış veri setlerinin yüklemesini gerçekleştiriyor, üst bloktaki gibi veriler W&B üzerinden artifact olarak yükleniyor\n\n+ config içinde tanımlanmış 5 adet dış veri üzerinde döngü oluşturulmuş\n+ her bir döngüde \"wandb.use_artifact(art)\" ile artifact değişkenine atanıyor\n+ \"artifact.download()\" kullanarak yükleniyor ve \"artifact_dir\" değişkenine atanıyor\n+ indirilen veriler parquet formatında yüklendiği için bunların okuması gerçekleşiyoe ve \"ext_df\" değişkenine atanıyor\n+ bu veriler concat kullanılarak mevcut train verileri ile birleştiriliyor\n---------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Prepare references and labels\n    reference_df = get_reference_df(config.raw_artifact)\n    all_labels = sorted(list(set(chain(*[x.tolist() for x in df.labels.values]))))\n    label2id = {l: i for i,l in enumerate(all_labels)}\n    id2label = {v:k for k,v in label2id.items()}\n    \n\"\"\"\n-----------------------------------------\n- modelin kullanıcağı referans df, tüm etiketler ve label2id, id2label oluşturulmuş\n\n+ \"reference_df\" değişkenine modelin tahminlerle karşılaştırcağı referans yani gerçek veri çerçevesi yüklenmiş\n+ chain fonksiyonu ile her satırdan alınan etiket dizeleri birleştirilip tek liste oluşturulmuş\n  + set ile liste içindeki uniq etiketler belirlenmiş\n  + sorted ile etiketler sıralanmış\n  + sıralanan tüm etiketler \"all_labels\" değişkenine atanmış\n+ enumerate ile tüm etiketler üzerinden label2id oluşturulmuş\n+ label2id üzerinden ters indeksleme ile id2label oluşturulmuş\n-----------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Create the training and validation datasets\n    tokenizer = AutoTokenizer.from_pretrained(config.training_model_path)\n    train_ds = create_dataset(train_df, tokenizer, config.training_max_length, label2id)\n    valid_ds = create_dataset(eval_df, tokenizer, config.inference_max_length, label2id)\n\n\"\"\"\n----------------------------------------\n- tokenizer ataması ve df'lerin tokenize edilip hazır hale getirilmesi sağlanmış\n\n+ model yolundan AutoTokenizer oluşturulmuş ve \"tokenizer\" değişkenine atanmış\n+ create_dataset fonksiyonu ile df'leri tokenize ederek ve indis atayarak verileri hazır hale getirmiş\n----------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Initialize the model and data collator\n    model = AutoModelForTokenClassification.from_pretrained(\n        config.training_model_path,\n        num_labels=len(all_labels),\n        id2label=id2label,\n        label2id=label2id,\n        ignore_mismatched_sizes=True\n    )\n    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n\n\"\"\"\n------------------------------------------\n- Modelin ve collator'un başlatılması sağlanmış\n\n+ model yolundan model başlatılmış\n  + \"num_labels\" veri kümesindeki toplam etiket sayısını belirtiyo\n  + id2label ve label2id eşleştirilerek sayısal kimliklerde eşleşme sağlanmış\n  + ignore_mismatched_sizes=True ile input boyutlarının modele uyum sağlamaması durumundaki uyarı mesajını engellemiş\n+ DataCollatorForTokenClassification ile modelin beklentilerine göre metin verilerinin girişini işler\n  + pad_to_multiple_of=16 ayarı ile her bir veri uzunluğunu modele göre ayarlamış\n------------------------------------------\n\"\"\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Define the training arguments\n    args = TrainingArguments(\n        output_dir=config.output_dir, \n        fp16=config.fp16,\n        learning_rate=config.learning_rate,\n        num_train_epochs=config.num_train_epochs,\n        per_device_train_batch_size=config.per_device_train_batch_size,\n        gradient_accumulation_steps=config.gradient_accumulation_steps,\n        report_to=config.report_to,\n        evaluation_strategy=config.evaluation_strategy,\n        do_eval=config.do_eval,\n        save_total_limit=config.save_total_limit,\n        logging_steps=config.logging_steps,\n        lr_scheduler_type=config.lr_scheduler_type,\n        warmup_ratio=config.warmup_ratio,\n        weight_decay=config.weight_decay,\n    )\n\n    # Calculate class weights based on your dataset (TODO: move to config)\n    class_weights = torch.tensor([1.]*12 + [config.o_weight]).to('cuda')\n    \n\"\"\"\n---------------------------------------------\n- eğitim argümanları atanmış ve ağırlıkları hesaplanmış\n\n+ \"class_weights\" değişkeni her bir sınıfın ağırlığını içerir\n  + dengesiz sınıf dağılımlarını engellemek için kullanılır\n  + torch.tensor kullanılarak ağırlık tensörü oluşturulmuş\n---------------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Initialize Trainer with custom class weights\n    trainer = CustomTrainer(\n        model=model, \n        args=args, \n        train_dataset=train_ds,\n        eval_dataset=valid_ds,\n        data_collator=collator, \n        tokenizer=tokenizer,\n        compute_metrics=partial(compute_metrics, id2label=id2label, valid_ds=valid_ds, valid_df=reference_df, threshold=config.threshold),\n        class_weights=class_weights,\n    )\n\n    # Train the model\n    trainer.train()\n\n    # Make predictions on the validation dataset\n    preds = trainer.predict(valid_ds)\n    \n\"\"\"\n----------------------------------------------\n- trainer değişkeninin özellikleri belirlenip train edilmeye başlanmış ardından tahminler \"preds\" değişkenine atanmış\n\n+ trainer değişkenine model yolu, argümanlar, datasetler, collektör, tokenizer, metrikler ve sınıf ağırlıkları bilgisi girilmiş\n+ trainer.train() ile eğitime başlanmış\n+ eğitilmiş modelin valis dataseti üzerindeki tahminleri elde edilmiş ve \"preds\" değişkenine atanmış\n\n----------------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Compute the final metrics and log them to Weights & Biases\n    print('Computing final metrics...')\n    final_metrics = {\n        f'final_f5_at_{threshold}': compute_metrics((preds.predictions, None), id2label, valid_ds, reference_df, threshold=threshold)['ents_f5']\n        for threshold in [0.5,0.6,0.7,0.8,0.9,0.95,0.97]\n    }\n    wandb.log(final_metrics)\n    print(final_metrics)\n    \n\"\"\"\n--------------------------------\n- hesaplanan metrikler W&B loguna kaydedilmiş ardından ekrana yazdırılmış\n\n+ \"final_metrics\" sözlüğüne metrikler girilmiş\n+ wandb.log komutu ile \"final_metrics\" loga kaydedilmiş\n+ print ile \"final_metrics\" ekrana yazdırılmış\n--------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # pick the best threshold from the final metrics and use it to generate preds_df\n    best_threshold = float(max(final_metrics, key=final_metrics.get).split('_')[-1])\n    wandb.config.best_threshold = best_threshold\n    preds_df = parse_predictions(preds.predictions, id2label, valid_ds, threshold=best_threshold)\n    \n\"\"\"\n------------------------------------------------\n- en iyi eşik değeri seçilerek W&B loguna kaydedilmiş ve df e dönüştürülmüş\n\n+ \"best_threshold\" değişkenine \"final_metrics\" sözlüğündeki en yüksek performanslı eşik değeri atanmış\n+ seçilen en iyi eşik değeri W&B config üzerinden W&B loguna kaydedilmiş\n+ \"parse_predictions\" fonksiyonu kullanılarak modelin tahminleri df'e dönüştürülmüş\n  + \"preds_df\" değişkenine df atanmış\n------------------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Prepare data to visualize errors and log them as a Weights & Biases table\n    print('Visualizing errors...')\n    grouped_preds = preds_df.groupby('eval_row')[['document', 'token', 'label', 'token_str']].agg(list)    \n    viz_df = pd.merge(eval_df.reset_index(), grouped_preds, how='left', left_on='index', right_on='eval_row')\n    viz_df = filter_errors(viz_df, preds_df)\n    viz_df['pred_viz'] = generate_htmls_concurrently(viz_df, tokenizer, preds.predictions, id2label, valid_ds, threshold=best_threshold)\n    nlp = spacy.blank(\"en\")\n    htmls = [visualize(row, nlp) for _,row in viz_df.iterrows()]\n    wandb_htmls = [wandb.Html(html) for html in htmls]\n    viz_df['gt_viz'] = wandb_htmls\n    viz_df.fillna(\"\", inplace=True)\n    viz_df = convert_for_upload(viz_df)\n    errors_table = wandb.Table(dataframe=viz_df)\n    wandb.log({'errors_table': errors_table})\n    \n\"\"\"\n------------------------------\n- hataların görselleştirilmesi için veri hazırlanmış ve hatalar W&B tablosu olarak günlüğe kaydedilmiş\n\n+ tahminler belgelere göre gruplanmış ve değerlendirme satırı \"eval_row\" temelinde toplanmış\n+ \"viz_df\" değişkenine hataların filtrelenmiş hali atanmış\n+ generate_htmls_concurrently kullanılarak hatalı tahminlerin HTML görselleştirmeleri oluşturulmuş\n+ SpaCy kütüphanesinin ingilizce dil modeli kullanılarak belgeler işlenmiş ve HTML görselleştirmesi oluşturulmuş\n+ HTML görselleri W&B de görüntülenebilir olması için wandb.html haline dönüştürülmüş\n+ HTML görselleştirmeleri ve diğer hata bilgileri W&B tablosuna dönüştürülerek \"errors_table\" adında tablo oluşturulmuş\n  + bu tablo W&B loguna kaydedilmiş\n------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Save the model and upload it to Kaggle\n    os.makedirs(config.experiment, exist_ok=True)\n    trainer.save_model(config.experiment)\n    # if training on a local machine, uncomment and fill in your username to upload the model to Kaggle\n    # upload_kaggle_dataset(config.experiment, config.experiment, owner=\"thedrcat\")\n    print('Experiment finished, test it out on the inference notebook!')\n\nif __name__ == \"__main__\":\n    parse_args(config)\n    main(config)\n\n\"\"\"\n------------------------------------------\n- oluşturulan model kaydedilmiş, opsiyonel olarak kaggle'a yüklemek istersek nasıl yükliyceğimiz anlatılmış.\n\n+ deney dizini oluşturulmuş veya olan bir deney dizini seçilmiş\n+ trainer.save_model ile model kaydedilmiş\n+ local bir makinede eğittiysek ve kaggle'a yüklemek istiyorsak upload_kaggle_dataset komutunu kullanabilceğimiz belirtilmiş\n  + owner değişkenine kullanıcı adımızı yazmamız gerekliymiş\n+ deneyin bitirildiğine dair ekrana print yazdırılmış\n------------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}