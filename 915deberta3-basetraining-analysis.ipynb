{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"},{"sourceId":163088908,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/emdogan/915-deberta3base-training-tercume?scriptVersionId=166933418\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## ğŸ›‘ Wait a second - after this you should also look at the inference notebook\n- My inference notebook (containing equally many emojis) is here:\n- https://www.kaggle.com/code/valentinwerner/893-deberta3base-inference","metadata":{}},{"cell_type":"markdown","source":"## ğŸŸï¸ Credits (because this baseline did mostly already exist when I joiend)\n\n- @Nicholas Broad published the transformer baseline which performs only marginally worse: https://www.kaggle.com/code/nbroad/transformer-ner-baseline-lb-0-854\n- @Joseph Josia published the training notebook which I basically copy pasted (which is based itself on nbroad, but yeah): https://www.kaggle.com/code/takanashihumbert/piidd-deberta-model-starter-training\n\n","metadata":{}},{"cell_type":"markdown","source":"## ğŸ’¡ What I added\n- Downsampling negative samples (samples without labels, but they possible still work as examples where names should not be tagged as name)\n- Adding @moths external data: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/469493\n- Adding PJMathematicianss external data: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/470921\n- However, I used my cleaned version instead (the punctuation is flawed in the original data set at the time of this trainign): https://www.kaggle.com/code/valentinwerner/fix-punctuation-tokenization-external-dataset\n\nDoing this brought the LB score to .888 - Trained in Kaggle Notebook, no tricks or secrets.\n\n- I added emojis because that seems to be the kaggle upvote meta","metadata":{}},{"cell_type":"markdown","source":"## ğŸ“ Config & Imports\n- 1024 max length has been working well for me. As some samples are longer, you may want to go as high as you can ","metadata":{}},{"cell_type":"code","source":"TRAINING_MODEL_PATH = \"microsoft/deberta-v3-base\"\nTRAINING_MAX_LENGTH = 1024\nOUTPUT_DIR = \"output\"\n\"\"\"\n-------------------------------------\n- Model iÃ§in ayarlamalar ve import gerÃ§ekleÅŸtirilmiÅŸ.\n\n+ TRAINING_MODEL_PATH: eÄŸitimde kullanÄ±lacak modelin adÄ± bu deÄŸiÅŸkene atanmÄ±ÅŸ, DeBERTa modeli kullanÄ±lmÄ±ÅŸ.\n+ TRAINING_MAX_LENGTH: eÄŸitimde kullanÄ±lacak maksimum giriÅŸ uzunluÄŸunu belirlenmiÅŸ.\n+ OUTPUT_DIR: eÄŸitim sÄ±rasÄ±nda oluÅŸturulan Ã§Ä±ktÄ± dosyalarÄ±nÄ±n kaydedileceÄŸi dizin belirtilmiÅŸ, Ã§Ä±ktÄ±larÄ±n \"output\" adlÄ± bir dizine \n  kaydedileceÄŸi belirlenmiÅŸ.\n-------------------------------------\n\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install seqeval evaluate -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport argparse\nfrom itertools import chain\nfrom functools import partial\n\nimport torch\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nfrom transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\nimport evaluate\nfrom datasets import Dataset, features\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ—ºï¸ Data Selection and Label Mapping\n- As mentioned before, I additionaly use the moth dataset","metadata":{}},{"cell_type":"code","source":"data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n\n# downsampling of negative examples\np=[] # positive samples (contain relevant labels)\nn=[] # negative samples (presumably contain entities that are possibly wrongly classified as entity)\nfor d in data:\n    if any(np.array(d[\"labels\"]) != \"O\"): p.append(d)\n    else: n.append(d)\n        \n# orjinal Ã¶rnek sayÄ±sÄ±\nprint(\"original datapoints: \", len(data))\n\n# ek veri setinin Ã¶rnek sayÄ±sÄ±\nexternal = json.load(open(\"/kaggle/input/fix-punctuation-tokenization-external-dataset/pii_dataset_fixed.json\"))\nprint(\"external datapoints: \", len(external))\n\n# ek veri setinin Ã¶rnek sayÄ±sÄ±\nmoredata = json.load(open(\"/kaggle/input/fix-punctuation-tokenization-external-dataset/moredata_dataset_fixed.json\"))\nprint(\"moredata datapoints: \", len(moredata))\n\n# tÃ¼m veri setinin Ã¶rnek sayÄ±sÄ±\ndata = moredata+external+p+n[:len(n)//3]\nprint(\"combined: \", len(data))\n\"\"\"\n--------------------------\n- ekstra datasetler import edilmiÅŸ ve Ã¶rnek sayÄ±larÄ± ekrana bastÄ±rÄ±lmÄ±ÅŸ\n\n+ \"data\" deÄŸiÅŸkenine yarÄ±ÅŸmanÄ±n kendi train seti import edilmiÅŸ\n+ Pozitif ve negatif deÄŸerler \"p\" ve \"n\" listelerine atanÄ±cak\n  + data deÄŸiÅŸkeni Ã¼zerinde dÃ¶ngÃ¼ baÅŸlatÄ±lmÄ±ÅŸ\n  + \"O\" etiketine sahip olmayan etiketler pozitif yani \"p\" listedine eklenmiÅŸ\n  + \"O\" etiketleri ise negatif yani \"n\" deÄŸiÅŸkenine atanmÄ±ÅŸ\n  + dÃ¶ngÃ¼ bittikten sonra orjinal data sayÄ±sÄ±nÄ± yani Ã¶rnek sayÄ±sÄ±nÄ± ekrana printlemiÅŸ\n+ dÄ±ÅŸardan dataset elde edilip \"external\" deÄŸiÅŸkenine import edilmiÅŸ\n  + ekrana bu ds'in kaÃ§ Ã¶rnek iÃ§erdiÄŸi yazdÄ±rÄ±lmÄ±ÅŸ\n+ \"moredata\" deÄŸiÅŸkenine dÄ±ÅŸardan baÅŸka ds yÃ¼klenmiÅŸ\n  + ekrana kaÃ§ Ã¶rnek iÃ§erdiÄŸi yazdÄ±rÄ±lmÄ±ÅŸ\n+ \"data\" deÄŸiÅŸkenine dÄ±ÅŸardan import edilen ds'ler dahil olmak Ã¼zere \"p\" ve \"n\" listeleri de dahil edilerek birleÅŸtirme yapÄ±lmÄ±ÅŸ\n  + combined adÄ± altÄ±nda tÃ¼m verilerin Ã¶rnek sayÄ±larÄ± ekrana yazdÄ±rÄ±lmÄ±ÅŸ\n--------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####\nall_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\nlabel2id = {l: i for i,l in enumerate(all_labels)}\nid2label = {v:k for k,v in label2id.items()}\n\ntarget = [\n    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n]\n\n# print(id2label)\n\n\"\"\"\n----------------------------\n- ds'lerimiz ile Ã¶nce tÃ¼m label'LarÄ±n listesi oluÅŸturulmuÅŸ, sonradÄ±nda her bir etiketin bir indeksle eÅŸleÅŸtirilmiÅŸ hali olan label2id ve \n  indekslerin etiketlere eÅŸleÅŸtirilmiÅŸ hali olan id2label sÃ¶zlÃ¼klerini oluÅŸturulmuÅŸ.\n\n+ tÃ¼m Ã¶rnekleri iÃ§eren \"data\" deÄŸiÅŸkenini dÃ¶ngÃ¼ye alarak chain fonksiyonu ile labels etiketleri tek liste haline getirilmiÅŸ, \"all_labels\" \n  listesine atanmÄ±ÅŸ\n  + set fonksiyonu ile listedeki labels'lar uniq hale getirilmiÅŸ yani her bir etiket listeye 1 defa eklenmiÅŸ\n  + list fonksiyonu ile oluÅŸturulan set bir liste haline getirilmiÅŸ\n  + sorted fonksiyonu ile bu liste alfabetik olarak sÄ±ralanmÄ±ÅŸ\n+ \"all_labels\" listesinden enumerate ile \"label2id\" oluÅŸturulmuÅŸ\n+ \"label2id\" kullanÄ±larak tam tersi yani id2label oluÅŸturulmuÅŸ\n+ target adÄ±nda bir liste oluÅŸturulmuÅŸ ve bu listede aradÄ±ÄŸÄ±mÄ±z etiketler sÄ±ralanmÄ±ÅŸ\n----------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## â™Ÿï¸ Data Tokenization\n- This tokenizer is actually special, comparing to usual NLP challenges","metadata":{}},{"cell_type":"code","source":"def tokenize(example, tokenizer, label2id, max_length):\n\n    # rebuild text from tokens\n    text = []\n    labels = []\n\n    for t, l, ws in zip(\n        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n    ):\n        text.append(t)\n        labels.extend([l] * len(t))\n\n        if ws:\n            text.append(\" \")\n            labels.append(\"O\")\n\n    \"\"\"\n    -------------------------------------------------------\n        + \"text\" ve \"labels\" listeleri oluÅŸturulmuÅŸ\n        + \"example\" sÃ¶zlÃ¼ÄŸÃ¼nden \"text\", \"labels\" ve \"trailing_whitespace\" deÄŸiÅŸkenleri ile dÃ¶ngÃ¼ oluÅŸturulmuÅŸ\n        + her bir token \"text\" listesine eklenmiÅŸ\n        + tokenin uzunluÄŸu kadar aynÄ± etiket birden Ã§ok kez labels'a eklenmiÅŸ Ã§Ã¼nkÃ¼ her bir karakter iÃ§in aynÄ± etiket geÃ§erli.\n        + eÄŸer tokenin ardÄ±ndan boÅŸluk karakteri varsa, boÅŸluk karakteri text listesine eklenmiÅŸ ve labels listesine de \"o\" etiketi \n          eklenmiÅŸ\n    -------------------------------------------------------\n    \"\"\"\n\n    # actual tokenization\n    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n\n    labels = np.array(labels)\n\n    text = \"\".join(text)\n    token_labels = []\n    \"\"\"\n    + tokenizer Ã§aÄŸÄ±rÄ±larak metin tokenize edilmiÅŸ ve \"tokenized\" deÄŸiÅŸkenine atanmÄ±ÅŸ\n    + \"\".join(text) ile metindeki tokenler birleÅŸtirilip tek dize hale getirilmiÅŸ\n    + return_offsets_mapping=True tokenin baÅŸlangÄ±Ã§ ve bitiÅŸ konumlarÄ±nÄ± takip eden offsetlerin return edilmesi saÄŸlanmÄ±ÅŸ\n    + uzunluk olarak daha Ã¶nce oluÅŸturduÄŸumuz \"max_length\" deÄŸiÅŸkeni kullanÄ±lmÄ±ÅŸ\n    + \"labels\" deÄŸiÅŸkenine etiketler numpy arry olarak atanmÄ±ÅŸ\n    + text deÄŸiÅŸkenine tÃ¼m tokenler birleÅŸtirilerek tekrardan atama yapÄ±lmÄ±ÅŸ\n    + \"token_labels\" adÄ±nda boÅŸ liste oluÅŸturulmuÅŸ\n    \"\"\"\n    for start_idx, end_idx in tokenized.offset_mapping:\n        # CLS token\n        if start_idx == 0 and end_idx == 0:\n            token_labels.append(label2id[\"O\"])\n            continue\n\n        # case when token starts with whitespace\n        if text[start_idx].isspace():\n            start_idx += 1\n\n        token_labels.append(label2id[labels[start_idx]])\n\n    length = len(tokenized.input_ids)\n\n    return {**tokenized, \"labels\": token_labels, \"length\": length}\n\n\"\"\"\n-----------------------------\n- tokenized fonksiyonu oluÅŸturulmuÅŸ metin, tokenizer, label2id ve uzunluk bilgilerini alarak metni tokenize etmemizi saÄŸlamÄ±ÅŸ, \n  return olarak tokenized metni, etiketleri ve uzunluklarÄ±nÄ± sÃ¶zlÃ¼k biÃ§iminde dÃ¶ndÃ¼rmÃ¼ÅŸ.\n  \n\n+ tokenin offset maplerini kullanarak etiketlerini belirlememizi saÄŸlayan bir dÃ¶ngÃ¼ baÅŸlatÄ±lmÄ±ÅŸ\n  + \"start_idx\" ve \"end_idx\" tokenin orjinal metindeki baÅŸlangÄ±Ã§ ve bitiÅŸ konumlarÄ±nÄ± ifade ediyor\n  + if ÅŸartÄ±nda tokenin CLS belirteÃ§i olup olmadÄ±ÄŸÄ±nÄ± kontrol edilmiÅŸ\n  + eÄŸer token CSL belirteÃ§i ise tokenin etiketi other \"O\" olarak belirlenir\n+ eÄŸer token boÅŸluk ile baÅŸlamÄ±ÅŸsa baÅŸlangÄ±Ã§ indeksine +1 eklenmiÅŸ\n+ indeksteki tokenin etiketi label2id sÃ¶zlÃ¼ÄŸÃ¼nden alÄ±narak token_labels listesine eklenmiÅŸ\n+ tokenized sÃ¶zlÃ¼ÄŸÃ¼ iÃ§indeki input_ids Ã¶ÄŸesinin uzunluÄŸu hesaplanmÄ±ÅŸ, tokenleÅŸtirilmiÅŸ metindeki toplam token sayÄ±sÄ± \"length\" deÄŸiÅŸkenine \n  atanmÄ±ÅŸ.\n+ return olarak sÃ¶zlÃ¼k dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ\n  + tokenized sÃ¶zlÃ¼ÄŸÃ¼ndeki tÃ¼m Ã¶geler kapsanmÄ±ÅŸ\n  + labels yani token etiketleri dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ\n  + lenght yani metindeki toplam token sayÄ±sÄ± dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ\n-----------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n\nds = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data],\n    \"document\": [str(x[\"document\"]) for x in data],\n    \"tokens\": [x[\"tokens\"] for x in data],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n    \"provided_labels\": [x[\"labels\"] for x in data],\n})\nds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": TRAINING_MAX_LENGTH}, num_proc=3)\n# ds = ds.class_encode_column(\"group\")\n\n\"\"\"\n--------------------------------------------\n- modelden hazÄ±r tokenizer oluÅŸturulmuÅŸ, ds oluÅŸturulup bunun Ã¼zerinde tokenizer uygulanmÄ±ÅŸ\n\n+ \"tokenizer\" deÄŸiÅŸkenine daha Ã¶nce eÄŸitilmiÅŸ modeldeki tokenizer atanmÄ±ÅŸ\n+ sÃ¶zlÃ¼kten bir ds oluÅŸturulmuÅŸ ve \"ds\" deÄŸiÅŸkenine atanmÄ±ÅŸ\n  + \"full_text\", \"document\", \"tokens\", \"trailing_whitespace\", \"provided_labels\" deÄŸiÅŸkenlerini iÃ§eriyor\n  + her bir deÄŸiÅŸken iÃ§in Ã¶nceden oluÅŸturduÄŸumuz \"data\" deÄŸiÅŸkenine dÃ¶ngÃ¼ oluÅŸturulmuÅŸ\n+ map fonksiyonu ile ds deÄŸiÅŸkenine tokenizasyon uygulanmÄ±ÅŸ\n  + kullanÄ±lacak iÅŸlemci Ã§ekirdeÄŸi 3 olarak belirlenmiÅŸ\n--------------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = ds[0]\n\nfor t,l in zip(x[\"tokens\"], x[\"provided_labels\"]):\n    if l != \"O\":\n        print((t,l))\n\nprint(\"*\"*100)\n\nfor t, l in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n    if id2label[l] != \"O\":\n        print((t,id2label[l]))\n        \n\"\"\"\n---------------------------------------\n- ds iÃ§indeki token ve etiketleri Ã§ift halinde \"o\" deÄŸilse ekrana bastÄ±rÄ±yor ardÄ±ndan dsdeki tokenleri input idlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor, \n  karÅŸÄ±lÄ±k gelen etiketleri yine Ã§ift halde olarak \"o\" deÄŸilse ekrana yazdÄ±rÄ±yor.\n\n+ ilk dÃ¶ngÃ¼ veri kÃ¼mesindeki Ã¶ÄŸenin tokenlerini ve saÄŸlanan etiketlerini (provided_labels) alÄ±r. Her bir token ve etiket Ã§ifti iÃ§in, \neÄŸer etiket \"O\" deÄŸilse tokeni ve etiketi yazdÄ±rÄ±r.\n+ ikinci dÃ¶ngÃ¼ veri kÃ¼mesindeki Ã¶ÄŸenin tokenlerini modelin giriÅŸ kimliklerine (input_ids) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Daha sonra, bu giriÅŸ kimliklerine \n  karÅŸÄ±lÄ±k gelen etiketleri (labels) alÄ±r. Her bir token ve etiket Ã§ifti iÃ§in, eÄŸer etiket \"O\" deÄŸilse, tokeni ve etiketi yazdÄ±rÄ±r. \n  +Burada id2label sÃ¶zlÃ¼ÄŸÃ¼ kullanÄ±larak etiketlerin anlamlÄ± hale dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi saÄŸlanÄ±r.\n---------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ§® Competition metrics\n- Note that we are not using the normal F1 score.\n- Although it is early in the competition, there are plenty of discsussions already explaining this:\n- e.g., here: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/470024","metadata":{}},{"cell_type":"code","source":"from seqeval.metrics import recall_score, precision_score\nfrom seqeval.metrics import classification_report\nfrom seqeval.metrics import f1_score\n\ndef compute_metrics(p, all_labels):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    \n    recall = recall_score(true_labels, true_predictions)\n    precision = precision_score(true_labels, true_predictions)\n    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n    \n    results = {\n        'recall': recall,\n        'precision': precision,\n        'f1': f1_score\n    }\n    return results\n\"\"\"\n-------------------------------------------\n- modelin performansÄ±nÄ± Ã¶lÃ§mek ve deÄŸerlendirmek iÃ§in Recall, Precision ve F1 skoru hesaplanmÄ±ÅŸ \"results\" sÃ¶zlÃ¼ÄŸÃ¼ne atanÄ±p return edilmiÅŸ\n\n+ modelden aldÄ±ÄŸÄ±mÄ±z sonuÃ§larÄ±n softmax ile en yÃ¼ksek olasÄ±lÄ±klÄ± olanÄ±nÄ± bulup her bir etiket iÃ§in o tokenin \n  en yÃ¼ksek ihtimalli etiketini seÃ§miÅŸ ve dizi oluÅŸturmuÅŸ bunu da predictions deÄŸiÅŸkenine atamÄ±ÅŸ\n+ her bir etiket iÃ§in tahmin ve gerÃ§ek etiketler dolaÅŸtÄ±rÄ±larak dÃ¶ngÃ¼ oluÅŸturulmuÅŸ,\n  + tahmin etiketler prediction deÄŸiÅŸkenine\n  + gerÃ§ek etiketler label etiketine atanÄ±r\n  + bu tahmin ve etiketler \"true_predictions\" ve \"true_labels\" deÄŸiÅŸkenlerine atanmÄ±ÅŸ\n+ hazÄ±r kÃ¼tÃ¼phaneler yardÄ±mÄ± ile Recall, Precision ve f1 hesaplanmÄ±ÅŸ ve deÄŸiÅŸkenlere atanmÄ±ÅŸ\n+ sonuÃ§lar \"result\" adlÄ± sÃ¶zlÃ¼kte birleÅŸtirilip return edilmiÅŸ\n-------------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    TRAINING_MODEL_PATH,\n    num_labels=len(all_labels),\n    id2label=id2label,\n    label2id=label2id,\n    ignore_mismatched_sizes=True\n)\ncollator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n\n\"\"\"\n---------------------------------\n- Ã¶nceden eÄŸitilmiÅŸ model ve collector iÃ§in \"model\" ve \"collator\" deÄŸiÅŸkenine atama yapÄ±lmÄ±ÅŸ \n---------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I decided to uses no eval\n# final_ds = ds.train_test_split(test_size=0.2, seed=42) # cannot use stratify_by_column='group'\n# final_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ‹ğŸ»â€â™€ï¸ Training\n- I actually do not use an eval set for submission to train on all data\n- Values are not really tuned and go by gut feeling, as this is my first iteration / baseline","metadata":{}},{"cell_type":"code","source":"# I actually chose to not use any validation set. This is only for the model I use for submission.\nargs = TrainingArguments(\n    output_dir=OUTPUT_DIR, \n    fp16=True,\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=2,\n    report_to=\"none\",\n    evaluation_strategy=\"no\",\n    do_eval=False,\n    save_total_limit=1,\n    logging_steps=20,\n    lr_scheduler_type='cosine',\n    metric_for_best_model=\"f1\",\n    greater_is_better=True,\n    warmup_ratio=0.1,\n    weight_decay=0.01\n)\n\ntrainer = Trainer(\n    model=model, \n    args=args, \n    train_dataset=ds,\n    data_collator=collator, \n    tokenizer=tokenizer,\n    compute_metrics=partial(compute_metrics, all_labels=all_labels),\n)\n\n\"\"\"\n----------------------------------\n- model iÃ§in argÃ¼man ve deÄŸiÅŸken atamasÄ± yapÄ±lmÄ±ÅŸ\n\n+ modelin kaydedilceÄŸi yer OUTPUT_DIR olarak belirlenmiÅŸ\n+ eÄŸitim sÄ±rasÄ±nda yarÄ± hassas hesaplama devre dÄ±ÅŸÄ± bÄ±rakÄ±lmÄ±ÅŸ\n  + fp16 hesaplama yapÄ±lÄ±rken daha az bellek kullanÄ±mÄ± ve daha hÄ±zlÄ± iÅŸlem yapÄ±lmasÄ±nÄ± saÄŸlayan bir tekniktir\n+ EÄŸitimde verilerin 3 tur eÄŸitilceÄŸi belirtilmiÅŸ, Her bir tur, tÃ¼m eÄŸitim verilerinin bir kez model tarafÄ±ndan geÃ§irilmesini ifade eder.\n+ eÄŸitim sÄ±rasÄ±ndaki raporlarÄ±n gÃ¶nderilmesi istenmemiÅŸ\n+ eÄŸitim sÄ±rasÄ±nda deÄŸerlendirme yapÄ±lmamasÄ± adÄ±na ayarlar yapÄ±lmÄ±ÅŸ\n+ en iyi modelin belirlenmesinde kullanÄ±lcak olan metrik f1 olarak belirlenmiÅŸ\n+ trainer sÄ±nÄ±fÄ±ndaki deÄŸiÅŸkenler iÃ§in yollar tek tek atanmÄ±ÅŸ\n----------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrainer.train()\n\"\"\"\n---------------------------------\n- eÄŸitim sÃ¼resini Ã¶lÃ§mek iÃ§in time komutu kullanÄ±larak eÄŸitim baÅŸlatÄ±lmÄ±ÅŸ.\n---------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ’¾ Save models\n- You can click on \"Save version\" (top right) and \"Save & Run All (Commit)\"\n- Then you can use this notebook as input for your inference notebook","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"deberta3base_1024\")\ntokenizer.save_pretrained(\"deberta3base_1024\")\n\n\"\"\"\n-----------------------------------------\n- trainer modeli ve tokenizer \"deberta3base_1024\" dizinine kaydedilmiÅŸ\n-----------------------------------------\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}